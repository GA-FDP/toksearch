{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data after pipeline computation\n",
    "\n",
    "A common use case of TokSearch is to aggregate the data in a results object for visualization, training a machine learning model, or performing statistical analysis. This notebook shows a few examples of how one might go about doing that.\n",
    "\n",
    "## Creating a simple pipeline\n",
    "\n",
    "We'll start be creating a very simple pipeline. This pipeline fetches flux-on-the-grid data from MDSplus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from toksearch import MdsSignal, Pipeline\n",
    "\n",
    "pipeline = Pipeline([165920, 165921, 173000])\n",
    "\n",
    "psirz_sig = MdsSignal(\n",
    "    r'\\psirz',                  \n",
    "    'efit01',\n",
    "    dims=('r', 'z', 'times'),\n",
    "    data_order=('times', 'r', 'z'),\n",
    ")\n",
    "\n",
    "pipeline.fetch_dataset('ds', {'psirz': psirz_sig})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside on ordering of dimensions\n",
    "Note that in creating the ```MdsSignal``` object, we had to be careful to specify the ```dims``` keyword argument along with the ```data_order``` keyword argument. This is done because the order in which MDSplus stores the coordinates for a node's dimensions doesn't necessarily correspond to the shape of the data that is being retrieved. In this case, MDSplus is set up such that ```dim_of(0)``` is the ```r``` coordinates, ```dim_of(1)``` is the ```z``` coordinates, and ```dim_of(2)``` is the ```times``` coordinates. However, the underlying Numpy ndarray has shape ('times', 'r', 'z').\n",
    "\n",
    "### Computing the data\n",
    "\n",
    "Now we go ahead and compute the pipeline. Recall that the object returned from the ```compute_*``` family of methods is a list-like object that can be iterated over. So, we can extract a list of xarray ```Dataset``` objects. This list can be used subsequently as a basis for a few types of aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pipeline.compute_serial()\n",
    "\n",
    "datasets = [rec['ds'] for rec in recs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ```xr.concat```\n",
    "\n",
    "One option is to create a new dataset that is concatenated along the ```shot``` dimension. Note that if, for example, the timebases are different (as they almost always will be), this methodology will leave you with some ```nan```s in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 16MB\n",
      "Dimensions:  (times: 312, r: 65, z: 65, shot: 3)\n",
      "Coordinates:\n",
      "  * times    (times) float32 1kB 100.0 120.0 140.0 ... 6.36e+03 6.38e+03\n",
      "  * r        (r) float32 260B 0.84 0.8666 0.8931 0.9197 ... 2.487 2.513 2.54\n",
      "  * z        (z) float32 260B -1.6 -1.55 -1.5 -1.45 -1.4 ... 1.45 1.5 1.55 1.6\n",
      "  * shot     (shot) int64 24B 165920 165921 173000\n",
      "Data variables:\n",
      "    psirz    (shot, times, r, z) float32 16MB -0.2949 -0.2961 -0.297 ... nan nan\n"
     ]
    }
   ],
   "source": [
    "combined_along_shot_dim = xr.concat(datasets, dim='shot')\n",
    "print(combined_along_shot_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can concatenate along the ```times``` dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 13MB\n",
      "Dimensions:  (shot: 3, r: 65, z: 65, times: 758)\n",
      "Coordinates:\n",
      "  * shot     (shot) int64 24B 165920 165921 173000\n",
      "  * r        (r) float32 260B 0.84 0.8666 0.8931 0.9197 ... 2.487 2.513 2.54\n",
      "  * z        (z) float32 260B -1.6 -1.55 -1.5 -1.45 -1.4 ... 1.45 1.5 1.55 1.6\n",
      "  * times    (times) float32 3kB 100.0 140.0 160.0 ... 5.4e+03 5.42e+03 5.44e+03\n",
      "Data variables:\n",
      "    psirz    (times, r, z) float32 13MB -0.2949 -0.2961 -0.297 ... 0.2966 0.2973\n"
     ]
    }
   ],
   "source": [
    "combined_along_times_dim = xr.concat(datasets, dim='times')\n",
    "print(combined_along_times_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to numpy ndarrays\n",
    "\n",
    "It is often useful to manipulate the dataset data directly as ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 65, 65)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndarrays = [ds['psirz'].values for ds in datasets]\n",
    "ndarrays[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of ndarrays can then be, for example, concatenated along the time dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758, 65, 65)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_array = np.concatenate(ndarrays, axis=0)\n",
    "big_array.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
