{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interesting-treatment",
   "metadata": {},
   "source": [
    "# Fully distributed execution with toksearch_submit (saga-only)\n",
    "\n",
    "\n",
    "The mechanism for distributing TokSearch computations is to invoke a TokSearch script using the ```toksearch_submit``` utility. Behind the scenes, ```toksearch_submit``` uses SLURM, and can be run in both interactive and batch modes, utilizing salloc and sbatch respectively. The default mode is to run interactively, using salloc.\n",
    "\n",
    "This will be demonstrated with an example script, adapted from the example above, and available in the TokSearch installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prepared-bargain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/opt/toksearch/users/sammuli/toksearch_dev/toksearch/envs/toksearch_dev/bin/python3.7\n",
      "# EASY-INSTALL-DEV-SCRIPT: 'toksearch==0.0.0','toksearch_example.py'\n",
      "__requires__ = 'toksearch==0.0.0'\n",
      "__import__('pkg_resources').require('toksearch==0.0.0')\n",
      "__file__ = '/opt/toksearch/users/sammuli/toksearch_dev/toksearch/scripts/toksearch_example.py'\n",
      "with open(__file__) as f:\n",
      "    exec(compile(f.read(), __file__, 'exec'))\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat $(which toksearch_example.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-nightlife",
   "metadata": {},
   "source": [
    "This script can be executed using either the ```compute_ray``` or ```compute_spark``` methods. First let's see how it works using Ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "macro-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ray with _temp_dir = /tmp/tmp3p8sp40m\n",
      "['10.0.0.43', '10.0.0.44', '10.0.0.45']\n",
      "STARTING CLUSTER\n",
      "--nodes=1 --ntasks=1 -w saga03 --gres=gpu:volta:1 --overlap --propagate ray start --block --node-ip-address 10.0.0.43 --temp-dir /tmp/tmp3p8sp40m --port 6543 --head --object-store-memory=95000000000 --memory=80000000000\n",
      "Ok, started head node\n",
      "dict_keys(['saga04', 'saga05'])\n",
      "Starting saga04...\n",
      "--nodes=1 --ntasks=1 -w saga04 --gres=gpu:volta:1 --overlap --propagate ray start --block --node-ip-address 10.0.0.44 --temp-dir /tmp/tmp3p8sp40m --address=10.0.0.43:6543 --object-store-memory=95000000000 --memory=80000000000\n",
      "Starting saga05...\n",
      "--nodes=1 --ntasks=1 -w saga05 --gres=gpu:volta:1 --overlap --propagate ray start --block --node-ip-address 10.0.0.45 --temp-dir /tmp/tmp3p8sp40m --address=10.0.0.43:6543 --object-store-memory=95000000000 --memory=80000000000\n",
      "********************************************************************************\n",
      "BATCH 1/1\n",
      "NUM CPUS: 96\n",
      "NUM PARTITIONS: 10000\n",
      "MEDIAN PARTITION SIZE: 1\n",
      "\u001b[2m\u001b[1m\u001b[36m(scheduler +19s, ip=10.220.24.154)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +19s, ip=10.220.24.154)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "Got 10000 results using ray\n",
      "\u001b[0msalloc -N 3 --exclusive --gres=gpu:volta:1 --x11=all srun -u --pty -N 1 --exclusive --propagate --gres=gpu:volta:0 --overlap toksearch_example.py ray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "salloc: Granted job allocation 15924\n",
      "salloc: Waiting for resource configuration\n",
      "salloc: Nodes saga[03-05] are ready for job\n",
      "srun: error: ioctl(TIOCGWINSZ): Inappropriate ioctl for device\n",
      "srun: error: Not using a pseudo-terminal, disregarding --pty option\n",
      "salloc: Relinquishing job allocation 15924\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Assume that this is being run on the saga login node and that you've done \"module load toksearch\"\n",
    "#toksearch_example.py ray\n",
    "\n",
    "# We'll run using 3 worker nodes. As of this writing there are 6 worker nodes available.\n",
    "toksearch_submit -N 3 toksearch_example.py -- ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-intro",
   "metadata": {},
   "source": [
    "Similarly, we can run with Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chief-purchase",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.0.0.43', '10.0.0.44', '10.0.0.45']\r\n",
      "STARTING CLUSTER\r\n",
      "MASTER IP 10.0.0.43\r\n",
      "['--nodes=1', '--ntasks=1', '-w', 'saga03', '--gres=gpu:volta:0', '--mem=150G', '/opt/toksearch/deps/spark/sbin/start-master.sh']\r\n",
      "Ok, started head node\r\n",
      "dict_keys(['saga03', 'saga04', 'saga05'])\r\n",
      "Starting saga03...\r\n",
      "['--nodes=1', '--ntasks=1', '-w', 'saga03', '--gres=gpu:volta:1', '--mem=150G', '/opt/toksearch/deps/spark/sbin/start-slave.sh', 'spark://10.0.0.43:7077', '-i', '10.0.0.43', '-c', 48, '-m', '149G']\r\n",
      "Starting saga04...\r\n",
      "['--nodes=1', '--ntasks=1', '-w', 'saga04', '--gres=gpu:volta:1', '--mem=150G', '/opt/toksearch/deps/spark/sbin/start-slave.sh', 'spark://10.0.0.43:7077', '-i', '10.0.0.44', '-c', 48, '-m', '149G']\r\n",
      "Starting saga05...\r\n",
      "['--nodes=1', '--ntasks=1', '-w', 'saga05', '--gres=gpu:volta:1', '--mem=150G', '/opt/toksearch/deps/spark/sbin/start-slave.sh', 'spark://10.0.0.43:7077', '-i', '10.0.0.45', '-c', 48, '-m', '149G']\r\n",
      "Got 10000 results using spark\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "salloc: Granted job allocation 7454\n",
      "srun: error: ioctl(TIOCGWINSZ): Inappropriate ioctl for device\n",
      "srun: error: Not using a pseudo-terminal, disregarding --pty option\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/03/24 08:34:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "\r",
      "[Stage 0:>                                                       (0 + 0) / 1000]\r",
      "[Stage 0:>                                                      (0 + 96) / 1000]\r",
      "[Stage 0:=>                                                    (19 + 96) / 1000]\r",
      "[Stage 0:==>                                                   (48 + 96) / 1000]\r",
      "[Stage 0:==>                                                   (52 + 96) / 1000]\r",
      "[Stage 0:===>                                                  (74 + 96) / 1000]\r",
      "[Stage 0:======>                                              (122 + 96) / 1000]\r",
      "[Stage 0:=======>                                             (145 + 96) / 1000]\r",
      "[Stage 0:==========>                                          (190 + 96) / 1000]\r",
      "[Stage 0:============>                                        (235 + 96) / 1000]\r",
      "[Stage 0:=============>                                       (254 + 96) / 1000]\r",
      "[Stage 0:===============>                                     (290 + 96) / 1000]\r",
      "[Stage 0:=================>                                   (322 + 96) / 1000]\r",
      "[Stage 0:===================>                                 (369 + 96) / 1000]\r",
      "[Stage 0:====================>                                (396 + 96) / 1000]\r",
      "[Stage 0:======================>                              (422 + 96) / 1000]\r",
      "[Stage 0:=======================>                             (450 + 96) / 1000]\r",
      "[Stage 0:==========================>                          (492 + 96) / 1000]\r",
      "[Stage 0:===========================>                         (519 + 96) / 1000]\r",
      "[Stage 0:=============================>                       (552 + 96) / 1000]\r",
      "[Stage 0:===============================>                     (595 + 96) / 1000]\r",
      "[Stage 0:================================>                    (610 + 96) / 1000]\r",
      "[Stage 0:==================================>                  (657 + 96) / 1000]\r",
      "[Stage 0:=====================================>               (701 + 96) / 1000]\r",
      "[Stage 0:=====================================>               (716 + 96) / 1000]\r",
      "[Stage 0:========================================>            (759 + 96) / 1000]\r",
      "[Stage 0:==========================================>          (797 + 96) / 1000]\r",
      "[Stage 0:===========================================>         (815 + 96) / 1000]\r",
      "[Stage 0:=============================================>       (850 + 96) / 1000]\r",
      "[Stage 0:==============================================>      (880 + 96) / 1000]\r",
      "[Stage 0:================================================>    (913 + 87) / 1000]\r",
      "[Stage 0:==================================================>  (952 + 48) / 1000]\r",
      "[Stage 0:====================================================>(987 + 13) / 1000]\r",
      "                                                                                \r",
      "salloc: Relinquishing job allocation 7454\n",
      "salloc: Job allocation 7454 has been revoked.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "toksearch_submit -N 3 toksearch_example.py -- spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-teens",
   "metadata": {},
   "source": [
    "## ```toksearch_submit``` syntax\n",
    "\n",
    "Now that we've seen a few examples, let's describe in a bit more detail what's actually going on. Taking one of the examples again:\n",
    "\n",
    "```bash\n",
    "toksearch__submit -N 3 toksearch_example.py -- spark\n",
    "```\n",
    "\n",
    "Let's break down the syntax:\n",
    "\n",
    "- ```-N 3```: This specifies the use of 3 worker nodes. As of this writing ```toksearch_submit``` only supports using entire nodes (and not a subset of cores within a node)\n",
    "\n",
    "- ```toksearch_example.py```: This is the script we want to run. We can alternatively invoke this as follows:\n",
    "    - ```toksearch_submit -N 3 python -- toksearch_example.py spark```\n",
    "    \n",
    "- ``` -- ```: The double-dash between the script and subsequent arguments is used to denote that everything following it are arguments that belong to the script, and not ```toksearch_submit```. So in this case ```spark``` is an argument to ```toksearch_example.py``` (and not an argument to ```toksearch_submit```)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-cameroon",
   "metadata": {},
   "source": [
    "## Getting help\n",
    "\n",
    "Help for ```toksearch_submit```, with a full listing of all options is available using the ```--help``` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abstract-craps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: toksearch_submit [-h] [-N NUM_NODES] [-b] [--config-file CONFIG_FILE]\n",
      "                        script [script_args [script_args ...]]\n",
      "\n",
      "positional arguments:\n",
      "  script                User-provided script\n",
      "  script_args           Arguments/options for user-provided script\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -N NUM_NODES, --num-nodes NUM_NODES\n",
      "                        Number of cluster nodes to use\n",
      "  -b, --batch           Run in batch mode (ie use sbatch)\n",
      "  --config-file CONFIG_FILE\n",
      "                        Config file used to set up slurm\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "toksearch_submit --help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
